# 빅데이터&인공지능 with 생물정보학

> 빅데이터&인공지능 with 생물정보학, 양우진, (주)아이콕스, 2019 를 읽고 정리한 것입니다.

<br>

## Chapter 01_생물정보학의 데이터

### 1-1 생물정보학과 빅데이터

#### 생물정보학(Bioinformatics)

: 수학과 통계, 컴퓨터 과학을 이용하여 방대한 양의 생물학 관련 데이터를 분석하고 유전자의 발현과 같은 생명 현상을 이해하기 위해 등장

<br>

#### 오믹스(Omics)

: 유전체 전체의 정보를 처리하는 과정

: 유전체(genome)은 유전자(gene)을 한데 묶은 것

<br>

#### 빅데이터

: 엄청 크고, 다양하며, 변화하는 데이터

: 3V

> 데이터의 양(Volume)
>
> 데이터 입출력의 속도(Velocity)
>
> 데이터 종류의 다양성(Variety)
>
> 다양한 V들이 추가되어 현재, 5V, 6V로 확장-정의되고 있다. 
>
> 가장 중요하게 볼 개념 => 가치(Value)
>
> 

<br>

### 1-2 개발 환경은 어떻게 마련하나?

#### 리눅스

: 리눅스는 대량의 데이터를 다루는 데에 가장 적합한 작업 환경을 제공

: 주로 우분투(Ubuntu)라는 리눅스 공개 운영체제를 설치하여 실행

: 셸 스크립트(shell script) 사용의 편리성으로 인해 데이터를 여러 형식으로 변경하거나 그 속에서 특정 데이터를 추출할 때 유용

<br>

#### 사용자 등록과 권한

: root 계정 = 시스템의 가장 최상위 권한을 가진 계정 ; 슈퍼유저, 이 권한으로 시스템 내의 모든 작업이 가능

: '관리자 권한'이 필요하다면 'sudo'를 사용

: 'su' 명령을 사용하면 사용자 전환을 바로 할 수 있다.

> 'su 계정' : 사용자 권한만 변경
>
> 'su - 계정' : 권한과 환경을 바꾸고 위치까지 이동 (새로 접속한 것과 같은 효과)

: $ passwd / passwd 아이디

> 패스워드를 변경할 때 / 해당 아이디의 패스워드 변경

: $ ls -al

> 디렉토리의 내용 확인
>
> '파일 이름'이 맨 마지막, 맨 첫 열의 'drwx-' 등으로 이루어진 문자열은 각 파일에 접근할 수 있는 권한

: drwx-

> 총 10개의 문자로 이루어짐
>
> 첫 문자는 'd' 또는 '-'이고 'directory 여부'를 알려준다. 
>
> 나머지 9개 문자는 총 3부분으로 나눌 수 있고, 각각 순서대로 [이 파일의 소유자가 가진 권한], [이 파일의 소유 그룹에 속한 사용자가 가진 권한], [이 서버의 모든 사용자가 가진 권한] 등을 뜻함
>
> 각 부분은 'rwx'로 구성되며 'r'은 read 권한, 'w'는 write 권한, 'x'는 excute 즉, '실행' 권한이 있음을 의미한다.=.
>
> 해당하는 자리에 '-'가 오게 되면 "그 권한이 없다"는 의미이다.

: 권한 다음에는 ''파일의 소유자''와 ''소유 그룹''이 나온다.

<br>

#### 예제

$ sudo groupadd TEST

> 그룹(TEST)을 만든다(groupadd).

$ sudo gpasswd -a test TEST

> 사용자(test)를 그룹에 추가(gpasswd)

$ su -test

> 계정을 바꾼다.

$ groups

> 어떤 group에 속하는지 알아보기

<br>

$ chown test:TEST .bashrc

> 파일 하나의 소유자를 '변경(chown)' 하기
>
> 소유자 변경 시 '사용자:그룹' 묶음으로 지정해 주면 된다.

$ chmod o-r .bashrc

> '모드 변경(chomd)' 명령을 통해 소유자와 그룹을 제외한 다른 사용자(other)에게서 읽기 권한(read)를 빼기

$ chmod g+w .bashrc

> 그룹(group)에게는 '쓰기(write)' 권한을 새로 부여하기

$ chmod 777

> +/- 형식이 아니라 전체 권한을 한방에 지정해주는 옵션

<br>

#### 여러 종류의 셸(Shell)

: 셸$ 

>  커서를 깜빡이면서 대기하다가 사용자가 입력한 명령어를 실행해 주는 것
>
> 사용자가 접속하면 권한에 따라 설정된 '셸의 종류'와 '홈 디렉토리'를 읽어서 해당 셸 프로그램을 실행한다.
>
> 즉, `셸은 명령어를 처리해 주는 사용자 인터페이스 프로그램` 

: 현재 리눅스에서 가장 많이 볼 수 있는 것은 바로 'bash'

: $ echo $SHELL

> 지금 접속해 있는 셸이 무엇인지 확인 할 때

: $ for i in 'ls *.bed'; do mv $i ${i%. \*}.BED; done

> 한 디렉토리 내의 모든 '.bed' 파일을 '.BED' 파일로 한꺼번에 바꿀 수 있다.

<br>

#### 셸의 명령어

$ ls

> 현재 디렉토리 내의 파일 목록을 보여달라

$ ls -al

> -al 옵션은 a(all)과 l(long)으로 모든 정보를 다 자세히 보여 달라는 뜻

$ ls -alF

> 디렉토리와 파일을 구분하고 실행 가능한 파일과 링크 등 각 구성 요소들의 속성까지 구분하여 출력하자면 '-F' 옵션을 붙인다.

$ alias abc= 'echo abc'

> 'alias'는 긴 명령어 중 자주 쓰는 것들을 별칭으로 지정할 때 사용한다. / 'alias' 라고만 입력하면 현재 지정된 목록을 전부 보여준다.
>
> [별칭 명령어 = '긴 명령어']
>
> echo는 변수를 출력하는 명령어 / 셸 스크립트와 배치 파일에서 주로 현재 상태를 화면이나 파일로 출력하는데 사용되는 내장 명령어
>
> 셸에서 지정한 alias는 셸을 빠져나가는 순간 없어지므로 새로 접속할 때에도 사라지지 않게 하려면 셸에 들어올 때마다 실행되는 비밀 파일인 '.bashrc' 안에 alias 명령을 넣어 둔다.

$ mkdir TEST

> 새로 빈 디렉토리를 현재 디렉토리의 아래에 만들 때
>
> 반대로, 지울 때는 'rmdir' (빈 디렉토리만 삭제 가능)

$ cd TEST

> 새로운 디렉토리로 이동 (cd, change directory)

$ pwd

> 현재 디렉토리의 정확한 위치 확인 시

$ echo ABC > new_file

> echo 명령어와 >를 사용하면 간단히 파일을 만들 수 있다.
>
> 이미 존재하는 파일인 경우 이전에 들어있던 내용은 모두 삭제 된다.
>
> 기존의 내용을 유지하고 새로운 문자열을 추가하려면 > 대신에 >>를 사용하면 된다.

$ cat new_file

> 텍스트 파일의 내용을 보기 위해서는 cat 명령어를 사용한다.
>
> 용량 큰 파일이나 명령 실행 결과를 순차적으로 확인할 때는 more 명령을 사용한다.

$ head ~/ .barshrc

> 어떤 형식인지 확인하기 위해서는 cat보다는 'head'를 사용한다.

$ tail -n3 /var/log/bootstrap.log

> 로그 파일과 같이 시간대별로 기록된 데이터의 경우라면, '마지막 부분'이 더 중요하기 때문에 head의 반대인 'tail'을 사용한다.

$ cp new_file old_file

> 파일을 복사할 경우에는 'cp' 명령어와 함께 '원본 파일의 이름'과 '새 파일의 이름'을 사용하면 된다.

$ mv old_file backup_file

> '복사'가 아닌 '이동'으로 파일을 옮길 때에는  'mv' 명령을 사용한다. 이름만 바꿀 때에도 사용 가능 / 디렉토리도 이동 가능

$ rm backup_file

> 파일을 지우고 싶을 때 사용
>
> 디렉토리도 지울 수 있지만 옵션이 필요하다.

$ ln -s new_file n

> 윈도우의 바로가기와 유사
>
> ln의 경우 -s 옵션을 많이 사용함. => '하드 링크'가 아닌 `심볼릭 링크`를 사용하라는 의미
>
> 원본 파일의 위치 정보만 가지고 있다가 일기나 쓰기를 할 때 그파일을 찾아 쓰는 것
>
> 원본 파일이 삭제 되면 링크는 남아있어도 사용 불가
>
> 하드 링크는 원본 파일의 일부 사본을 생성하는데, 사실상 같은 내용을 공유하는 여러 개의 파일처럼 사용한다.

$ df -h

> -h 는 human-readable
>
> 현재 하드디스크를 얼마나 쓰고 있는지

$ du . -hs

> 내가 얼마나 점유하고 있는지 알고 싶다면 'du' 명령을 사용한다. / 현재 디렉토리와 그 자식 디렉토리의 모든 파일 크기의 합계를 알기 위한 명령
>
> 옵션 -h는 위와 같고, -s는 요약해서 보여달라는 의미

$ top

> 서버의 CPU나 memory를 얼마나 사용하고 있는지를 알 수 있는 명령어

<br>

#### 파일 편집기

: vi 편집기 => vim편집기가 vi를 대체 (대부분 리눅스에서 vi라고 입력하면 vim이 나타난다.)

: vi 보다 쉬운 에디터로 nano 에디터가 있다.

<br>

### 1-3 빅데이터는 어디서 구하나?

: 유전체 데이터의 파일 형식은 대체로 'bed' 파일이나 'tsv, csv' 등의 텍스트 파일로 되어 있다.

<br>

#### 스크립트로 데이터 긁어오기

: 웹에서 파일을 다운로드하는 유틸리티로는 'weget, curl' 등이 있고, URL만 알고 있다면 파일을 받을 수 있다.

: 파일을 받을 때에는 'weget'이 더 편리하다.

<br>

## Chapter 02 데이터 다루기

### 2.1 빅데이터는 어떻게 저장할까?

#### 데이터 전처리(preprocessing)

: 데이터 수집 과정이 완벽하지 않기에 노이즈도 있고 이름이 잘못 붙은 데이터도 많다. 이러한 데이터를 걸러주는 과정이 분석에 앞서 필요하다.

: 데이터 분석을 위해 필요한 데이터를 추출하는 전 과정을 **전처리**라고 한다.

: 좁은 의미에서는 원본 데이터에서 에러를 줄이는 것을 의미한다.

: 전처리를 거친 데이터를 가공하고 필요없는 데이터를 없애거나 여러 데이터를 합쳐서 내가 원하는 종류의 데이터로 바꾸는 작업은 **데이터 랭글링(wrangling)**이라고 한다.

<br>

### 2.2 데이터 처리를 위한 방법

#### 여러 데이터 형식

**파일 형식(format)**

: 정보를 저장하기 위해 인코딩(encoding) 하는 방식을 의미

: 컴퓨터는 모든 데이터를 비트 단위로 즉 0 또는 1의 연속으로만 저장할 수 있기 때문에 원본 데이터를 0과 1로만 이루어진 암호(code)로 바꿔야 한다.

: 유전체 시퀀싱 정보를 다룰 때 가장 단순한 파일 형식은 **'FASTA'** 파일이다.

: 실험을 통해 얻은 시퀀스는 '**FASTQ'** 형식으로 저장되어 있는 경우가 많다.

: **FASTA**는 시퀀스만 쓴 것이고 **FASTQ**는 여기에 '품질(quality)' 정보를 더한 것

<br>

**NGS(차세대 지놈 시퀀싱)** 

: 한 가닥의 DNA를 시퀀싱하는 것이 어렵기 때문에 복제를 해서 같은 시퀀스를 가진 다발을 만든 뒤에 DNA 다발이 발생시키는 신호를 측정해서 그 서열 정보를 알아내는 것이다.

: 신호를 발생시키는 화학 반응 과정에서 오류가 발생한다면 DNA 다발에 다른 서열이 끼어들게 된다. 이러한 오류가 몇 퍼센트나 되는 지에 따라 품질이 달라지게 된다. 품질을 해석해서 특정 시퀀스가 개인이 가진 돌연변이인지, 시퀀싱 오류인지를 판단하기 때문에 중요한 데이터라 할 수 있다.

<br>

**FASTQ 파일**

: 4줄이 한 세트

: 첫 번째 라인은 '@'로 시작하며, 아이디 정보와 함께 다른 정보를 사용할 수 있다.

: 두 번째 라인은 시퀀스를 그대로 쭉 쓴다.

: 세 번째 라인은 '+' 인데 뒤에 아이디를 넣기도 하지만 아무것도 안 쓰는 경우도 많다.

: 마지막 라인에는 품질 정보가 들어있다.

> '!(ASCII 코드의 33번)'가 가장 낮은 품질을, '~(ASCII 92번)'이 가장 높은 품질을 뜻한다.

: 코드 표를 보면서 해석할 수는 있지만, FASTQ를 다룰 수 있는 전용 툴을 사용해서 처리하는 것이 좋다.

<br>

**Alignment (or Mapping)**

: 위치를 찾는 것을 '얼라이먼트(alignment)'라고 하고, 간단히 '매핑'이라고도 한다.

: 그 결과를 'sam(Sequence Alignment Map)' 이나 'bam(Binary Alignment Map)' 파일에 담는다.

: 변이를 찾는 것은 **'콜링(calling)'**이라고 하고 번역해서 '추출'이라고 부르기도 하는데, 주로 vcf 파일에 담는다.

<br>

**sam파일 bam파일**

: 얼라이먼트 결과는 sam 파일 형식으로 담는다.

: bam 파일은 크기를 줄이기 위해 sam을 바이너리 형식으로 바꾼 것으로 sam과 같다고 보면 된다.

: 얼라이먼트는 레퍼런스 시퀀스와  fastq 파일에 담겨있는 조각 시퀀스를 비교한 것이기 때문에, 레퍼런스에서 어느 위치에 속하는지 알 수 있고 레퍼런스와의 차이를 찾을 수 있기 해준다.

: 얼라이먼트가 얼마나 잘되는지를 나타내는 것이 바로 **'매핑 품질(MAPQ)'**이다. 

: 예를 들어 '8M2I4M1D3M' 이라고 쓰여있다면 해당 시퀀스가 레퍼런스와 비교했을 때, 8개 일치, 2개 추가, 4개 일치, 1개 삭제, 3개 일치한다는 뜻으로 해석한다.

: 대부분은 samtools를 사용해서 처리한다.

<br>

**bed 포맷**

: 어떤 단백질에 붙어 있는 시퀀스를 모두 모아서 유전체의 어느 부분인지 알고 싶다고 하면 sam 파일 중에서도 위치 정보가 가장 중요하다. 

: 이렇게 위치만 빼서 따로 만들 때 쓰는 파일이 바로 bed 포맷이다. 

: bed 포맷을 다룰 때 쓰는 것이 bedtools 이다.

: merge 기능을 이용하여 파일을 합칠 수 있다. 만약 2개의 bed 파일을 합칠 때, 하나의 bed 파일 안에는 서로 겹치는 위치가 있을 수 있어 하나의 유전 변이가 여러 군데 겹치는 것처럼 나올 수 있다. 이때, merge를 이용하면 겹치는 부분을 하나로 합칠 수 있다.

: 두 bed 파일에서 서로 겹치는 부분을 빼내고 싶으면 intersect를 쓰면 된다. 새로 찾아낸 돌연변이를 bed 파일로 가지고 있을 때, 다른 데이터와 실제로 겹치는지 알고 싶을 때는 intersect를 쓰게 된다.

: intersect 사용 시 'loj' 옵션을 사용하면 두 테이블을 합칠 때 왼쪽(처음 나오는 쪽) 테이블을 기준으로 합친다. 이 옵션을 사용하면 실제로 안겹치는 경우에도 테이블을 남겨두고 대신 -1로 표시해서 겹치는 데이터가 없다는 것을 명시해줌

<br>

**콜링**

: 위치가 아니라 특정 개인이나 암세포가 가진 유전 변이 정보만 추출하고 싶으면 콜링을 하게 된다.

: 특정 위치에 레퍼런스와의 차이가 반복해서 나타나고, 또 충분히 높은 시퀀싱 품질을 가지고 있다면 그 부분은 오류가 아니라 변이가 확실하다고 할 수 있다.

: 변이가 확실한 부분만 따로 담은 파일이 바로 vcf 파일이다.

: sam(bam) 파일에서 vcf를 만드는 방법 중에서 samtools에 포함된 bcftools도 있고, GATK의 파이프라인(pipeline)도 있다.

<br>

**파이프라인**

: 유전체 데이터는 여러 단계를 거치면서 분석하는데, 각 단계마다 적용이 가능한 많은 툴들이 존재한다. 원하는 데이터를 추출하기 위해 단계 마다 각각의 툴들을 잘 엮어 놓은 것이 바로 파이프라인이다. 

: 마치 공장 라인처럼 데이터를 순서대로 쭉 가공해서 결과물을 내놓는 것

: 파이프라인은 컴퓨터 CPU에서 매우 중요한 개념이기도 하며, 모든 장비가 계속 사용중인 상태로 input과 output이 끊임없이 진행되면 전체 성능이 3배로 빨라지는데, 이것이 파이프라인의 원리이다.

: CPU에서는 여러 단계를 거쳐 명령을 처리 한다. 복잡한 단계에서 간단한 일을 처리해야하므로 많은 문제가 생기는데 그 중 CPU가 아무 일도 하지 않는 타이밍이 생기게 된다. 이 것을 버블이라고 부른다. 버블은 성능 저하의 원인이 되기 때문에 줄이기 위해 많은 노력을 해오고 있다.











